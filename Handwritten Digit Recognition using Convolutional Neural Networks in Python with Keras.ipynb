{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition using Convolutional Neural Networks in Python with Keras\n",
    "http://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular demonstration of the capability of deep learning techniques is object recognition in image data.\n",
    "\n",
    "The “hello world” of object recognition for machine learning and deep learning is the MNIST dataset for handwritten digit recognition.\n",
    "\n",
    "In this post you will discover how to develop a deep learning model to achieve near state of the art performance on the MNIST handwritten digit recognition task in Python using the Keras deep learning library.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "How to load the MNIST dataset in Keras.\n",
    "How to develop and evaluate a baseline neural network model for the MNIST problem.\n",
    "How to implement and evaluate a simple Convolutional Neural Network for MNIST.\n",
    "How to implement a close to state-of-the-art deep learning model for MNIST.\n",
    "Let’s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the MNIST Handwritten Digit Recognition Problem\n",
    "\n",
    "The [MNIST](http://yann.lecun.com/exdb/mnist/) problem is a dataset developed by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models on the handwritten digit classification problem.\n",
    "\n",
    "The dataset was constructed from a number of scanned document dataset available from the [National Institute of Standards and Technology](http://www.nist.gov/) (NIST). This is where the name for the dataset comes from, as the Modified NIST or MNIST dataset.\n",
    "\n",
    "Images of digits were taken from a variety of scanned documents, normalized in size and centered. This makes it an excellent dataset for evaluating models, allowing the developer to focus on the machine learning with very little data cleaning or preparation required.\n",
    "\n",
    "Each image is a 28 by 28 pixel square (784 pixels total). A standard spit of the dataset is used to evaluate and compare models, where 60,000 images are used to train a model and a separate set of 10,000 images are used to test it.\n",
    "\n",
    "It is a digit recognition task. As such there are 10 digits (0 to 9) or 10 classes to predict. Results are reported using prediction error, which is nothing more than the inverted classification accuracy.\n",
    "\n",
    "Excellent results achieve a prediction error of less than 1%. State-of-the-art prediction error of approximately 0.2% can be achieved with large Convolutional Neural Networks. There is a listing of the state-of-the-art results and links to the relevant papers on the MNIST and other datasets on [Rodrigo Benenson’s webpage](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MNIST dataset in Keras\n",
    "\n",
    "The Keras deep learning library provides a convenience method for loading the MNIST dataset.\n",
    "\n",
    "The dataset is downloaded automatically the first time this function is called and is stored in your home directory in ~/.keras/datasets/mnist.pkl.gz as a 15MB file.\n",
    "\n",
    "This is very handy for developing and testing deep learning models.\n",
    "\n",
    "To demonstrate how easy it is to load the MNIST dataset, we will first write a little script to download and visualize the first 4 images in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD+CAYAAABFjqJ0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1be8ac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ad hoc mnist instances\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "# show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model with Multi-Layer Perceptrons\n",
    "\n",
    "Do we really need a complex model like a convolutional neural network to get the best results with MNIST?\n",
    "\n",
    "You can get very good results using a very simple neural network model with a single hidden layer. In this section we will create a simple multi-layer perceptron model that achieves an error rate of 1.74%. We will use this as a baseline for comparing more complex convolutional neural network models.\n",
    "\n",
    "Let’s start off by importing the classes and functions we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good idea to initialize the random number generator to a constant to ensure that the results of your script are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the MNIST dataset using the Keras helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is structured as a 3-dimensional array of instance, image width and image height. For a multi-layer perceptron model we must reduce the images down into a vector of pixels. In this case the 28×28 sized images will be 784 pixel input values.\n",
    "\n",
    "We can do this transform easily using the [reshape() function](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.reshape.html) on the NumPy array. We can also reduce our memory requirements by forcing the precision of the pixel values to be 32 bit, the default precision used by Keras anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values are gray scale between 0 and 255. It is almost always a good idea to perform some scaling of input values when using neural network models. Because the scale is well known and well behaved, we can very quickly normalize the pixel values to the range 0 and 1 by dividing each value by the maximum of 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the output variable is an integer from 0 to 9. This is a multi-class classification problem. As such, it is good practice to use a one hot encoding of the class values, transforming the vector of class integers into a binary matrix.\n",
    "\n",
    "We can easily do this using the built-in np_utils.to_categorical() helper function in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to create our simple neural network model. We will define our model in a function. This is handy if you want to extend the example later and try and get a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, init='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, init='normal', activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a simple neural network with one hidden layer with the same number of neurons as there are inputs (784). A rectifier activation function is used for the neurons in the hidden layer.\n",
    "\n",
    "A softmax activation function is used on the output layer to turn the outputs into probability-like values and allow one class of the 10 to be selected as the model’s output prediction. Logarithmic loss is used as the loss function (called categorical_crossentropy in Keras) and the efficient ADAM gradient descent algorithm is used to learn the weights.\n",
    "\n",
    "We can now fit and evaluate the model. The model is fit over 10 epochs with updates every 200 images. The test data is used as the validation dataset, allowing you to see the skill of the model as it trains. A verbose value of 2 is used to reduce the output to one line for each training epoch.\n",
    "\n",
    "Finally, the test dataset is used to evaluate the model and a classification error rate is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6s - loss: 0.2791 - acc: 0.9203 - val_loss: 0.1421 - val_acc: 0.9578\n",
      "Epoch 2/10\n",
      "6s - loss: 0.1123 - acc: 0.9679 - val_loss: 0.0998 - val_acc: 0.9696\n",
      "Epoch 3/10\n",
      "6s - loss: 0.0724 - acc: 0.9789 - val_loss: 0.0786 - val_acc: 0.9746\n",
      "Epoch 4/10\n",
      "6s - loss: 0.0510 - acc: 0.9855 - val_loss: 0.0788 - val_acc: 0.9761\n",
      "Epoch 5/10\n",
      "6s - loss: 0.0366 - acc: 0.9898 - val_loss: 0.0638 - val_acc: 0.9795\n",
      "Epoch 6/10\n",
      "6s - loss: 0.0265 - acc: 0.9929 - val_loss: 0.0643 - val_acc: 0.9798\n",
      "Epoch 7/10\n",
      "6s - loss: 0.0185 - acc: 0.9958 - val_loss: 0.0609 - val_acc: 0.9807\n",
      "Epoch 8/10\n",
      "6s - loss: 0.0147 - acc: 0.9969 - val_loss: 0.0620 - val_acc: 0.9812\n",
      "Epoch 9/10\n",
      "6s - loss: 0.0106 - acc: 0.9981 - val_loss: 0.0599 - val_acc: 0.9816\n",
      "Epoch 10/10\n",
      "6s - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0594 - val_acc: 0.9819\n",
      "Baseline Error: 1.81%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example might take a few minutes when run on a CPU. You should see the output above. This very simple network defined in very few lines of code achieves a respectable error rate of 1.74%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Convolutional Neural Network for MNIST\n",
    "\n",
    "Now that we have seen how to load the MNIST dataset and train a simple multi-layer perceptron model on it, it is time to develop a more sophisticated convolutional neural network or CNN model.\n",
    "\n",
    "Keras does provide a lot of capability for [creating convolutional neural networks](http://keras.io/layers/convolutional/).\n",
    "\n",
    "In this section we will create a simple CNN for MNIST that demonstrates how to use all of the aspects of a modern CNN implementation, including Convolutional layers, Pooling layers and Dropout layers.\n",
    "\n",
    "The first step is to import the classes and functions needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we always initialize the random number generator to a constant seed value for reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to load the MNIST dataset and reshape it so that it is suitable for use training a CNN. In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions [pixels][width][height].\n",
    "\n",
    "In the case of RGB, the first dimension pixels would be 3 for the red, green and blue components and it would be like having 3 image inputs for every color image. In the case of MNIST where the pixel values are gray scale, the pixel dimension is set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, it is a good idea to normalize the pixel values to the range 0 and 1 and one hot encode the output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our neural network model.\n",
    "\n",
    "Convolutional neural networks are more complex than standard multi-layer perceptrons, so we will start by using a simple structure to begin with that uses all of the elements for state of the art results. Below summarizes the network architecture.\n",
    "\n",
    "1. The first hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, which with the size of 5×5 and a rectifier activation function. This is the input layer, expecting images with the structure outline above [pixels][width][height].\n",
    "2. Next we define a pooling layer that takes the max called MaxPooling2D. It is configured with a pool size of 2×2.\n",
    "3. The next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    "4. Next is a layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n",
    "5. Next a fully connected layer with 128 neurons and rectifier activation function.\n",
    "6. Finally, the output layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like predictions for each class.\n",
    "\n",
    "As before, the model is trained using logarithmic loss and the ADAM gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model the same way as before with the multi-layer perceptron. The CNN is fit over 10 epochs with a batch size of 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "95s - loss: 0.2412 - acc: 0.9318 - val_loss: 0.0752 - val_acc: 0.9766\n",
      "Epoch 2/10\n",
      "95s - loss: 0.0727 - acc: 0.9780 - val_loss: 0.0531 - val_acc: 0.9829\n",
      "Epoch 3/10\n",
      "97s - loss: 0.0498 - acc: 0.9850 - val_loss: 0.0390 - val_acc: 0.9857\n",
      "Epoch 4/10\n",
      "97s - loss: 0.0417 - acc: 0.9867 - val_loss: 0.0420 - val_acc: 0.9859\n",
      "Epoch 5/10\n",
      "94s - loss: 0.0326 - acc: 0.9897 - val_loss: 0.0394 - val_acc: 0.9860\n",
      "Epoch 6/10\n",
      "574s - loss: 0.0287 - acc: 0.9910 - val_loss: 0.0423 - val_acc: 0.9857\n",
      "Epoch 7/10\n",
      "98s - loss: 0.0224 - acc: 0.9929 - val_loss: 0.0323 - val_acc: 0.9892\n",
      "Epoch 8/10\n",
      "96s - loss: 0.0202 - acc: 0.9936 - val_loss: 0.0370 - val_acc: 0.9885\n",
      "Epoch 9/10\n",
      "96s - loss: 0.0160 - acc: 0.9951 - val_loss: 0.0321 - val_acc: 0.9888\n",
      "Epoch 10/10\n",
      "95s - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0315 - val_acc: 0.9891\n",
      "Baseline Error: 1.09%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example, the accuracy on the training and validation test is printed each epoch and at the end of the classification error rate is printed.\n",
    "\n",
    "Epochs may take 60 to 90 seconds to run on the CPU, or about 15 minutes in total depending on your hardware. You can see that the network achieves an error rate of 1.10, which is better than our simple multi-layer perceptron model above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger Convolutional Neural Network for MNIST\n",
    "\n",
    "Now that we have seen how to create a simple CNN, let’s take a look at a model capable of close to state of the art results.\n",
    "\n",
    "We import classes and function then load and prepare the data the same as in the previous CNN example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we define a large CNN architecture with additional convolutional, max pooling layers and fully connected layers. The network topology can be summarized as follows.\n",
    "\n",
    "1. Convolutional layer with 30 feature maps of size 5×5.\n",
    "2. Pooling layer taking the max over 2*2 patches.\n",
    "3. Convolutional layer with 15 feature maps of size 3×3.\n",
    "4. Pooling layer taking the max over 2*2 patches.\n",
    "5. Dropout layer with a probability of 20%.\n",
    "6. Flatten layer.\n",
    "7. Fully connected layer with 128 neurons and rectifier activation.\n",
    "8. Fully connected layer with 50 neurons and rectifier activation.\n",
    "9. Output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the previous two experiments, the model is fit over 10 epochs with a batch size of 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-42e5e669f1aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Final evaluation of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mc:\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    789\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\keras\\backend\\theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\theano\\tensor\\blas.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inp, out)\u001b[0m\n\u001b[0;32m   1821\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m             \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m             \u001b[1;31m# The error raised by numpy has no shape information, we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = larger_model()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints accuracy on the training and validation datasets each epoch and a final classification error rate.\n",
    "\n",
    "The model takes about 100 seconds to run per epoch. This slightly larger model achieves the respectable classification error rate of 0.89%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not an optimized network topology. Nor is a reproduction of a network topology from a recent paper. There is a lot of opportunity for you to tune and improve upon this model.\n",
    "\n",
    "What is the best error rate score you can achieve?\n",
    "\n",
    "Post your configuration and best score in the comments.\n",
    "\n",
    "## Resources on MNIST\n",
    "\n",
    "The MNIST dataset is very well studied. Below are some additional resources you might like to look into.\n",
    "\n",
    "- [The Official MNIST dataset webpage](http://yann.lecun.com/exdb/mnist/).\n",
    "- [Rodrigo Benenson’s webpage that lists state of the art results](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354).\n",
    "- [Kaggle competition that uses this dataset](https://www.kaggle.com/c/digit-recognizer) (check the scripts and forum sections for sample code)\n",
    "- [Read-only model trained on MNIST that you can test in your browser](http://myselph.de/neuralNet.html) (very cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
